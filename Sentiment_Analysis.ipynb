{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb440365-b015-4714-bdf1-f7c3f91a19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd7453-5c7d-4eb9-b69c-8732e4149690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the stock data files\n",
    "folder_path = 'price/preprocessed'\n",
    "\n",
    "# Create a dictionary to store the dataframes for each company\n",
    "company_data = {}\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):  # Check if the file is a text file\n",
    "        company_name = filename[:-4]  # Use the filename (without the .txt) as the company name\n",
    "\n",
    "        # Load the data into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path, delimiter=\"\\t\", header=None,\n",
    "                         names=[\"Date\", \"Movement %\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "\n",
    "        # Convert the 'Date' column to datetime\n",
    "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "        # Store the DataFrame in the dictionary with the company name as the key\n",
    "        company_data[company_name] = df\n",
    "\n",
    "# Example: Access the DataFrame for a specific company (e.g., 'AAPL')\n",
    "AAPL_df = company_data['AAPL']\n",
    "AMZN_df = company_data['AMZN']\n",
    "CHL_df = company_data['CHL']\n",
    "CSCO_df = company_data['CSCO']\n",
    "FB_df = company_data['FB']\n",
    "GOOG_df = company_data['GOOG']\n",
    "INTC_df = company_data['INTC']\n",
    "MSFT_df = company_data['MSFT']\n",
    "ORCL_df = company_data['ORCL']\n",
    "T_df = company_data['T']\n",
    "TSM_df = company_data['TSM']\n",
    "VZ_df = company_data['VZ']\n",
    "\n",
    "print(ORCL_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86459e02-234c-4a34-8c6c-c6713c243292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Movement % over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(AAPL_df['Date'], AAPL_df['Movement %'], label='Movement %')\n",
    "plt.title(\"AAPL - Movement % Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Movement %\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feab2eb1-79b3-4b74-ba78-5606fce7d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_df['Smoothed'] = AAPL_df['Movement %'].rolling(window=5).mean()\n",
    "plt.plot(AAPL_df['Date'], AAPL_df['Smoothed'], label='5-day Avg', color='orange')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe426e-dfce-4ade-be89-a351d8633126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_movement(company_data, ticker, window=14):\n",
    "    \"\"\"\n",
    "    Plot raw and smoothed Movement % over time for a given company.\n",
    "\n",
    "    Parameters:\n",
    "        company_data (dict): Dictionary of DataFrames keyed by ticker symbol.\n",
    "        ticker (str): The ticker symbol of the company to plot (e.g., 'AAPL').\n",
    "        window (int): Rolling window size for smoothing (default is 5 days).\n",
    "    \"\"\"\n",
    "    if ticker not in company_data:\n",
    "        print(f\"Ticker '{ticker}' not found in company data.\")\n",
    "        return\n",
    "\n",
    "    df = company_data[ticker].copy()\n",
    "    \n",
    "    # Ensure the data is sorted by date\n",
    "    df = df.sort_values(by='Date')\n",
    "\n",
    "    # Compute the smoothed values\n",
    "    df['Smoothed'] = df['Movement %'].rolling(window=window).mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df['Date'], df['Movement %'], label='Raw Movement %', alpha=0.7)\n",
    "    plt.plot(df['Date'], df['Smoothed'], label=f'Smoothed ({window}-day Avg)', color='orange', linewidth=2)\n",
    "\n",
    "    plt.title(f\"{ticker} - Raw vs Smoothed Movement % Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Movement %\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38daf2-ec2c-4798-ae58-3a14de93ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_close(company_data, ticker, window=14):\n",
    "    \"\"\"\n",
    "    Plot raw and smoothed Movement % over time for a given company.\n",
    "\n",
    "    Parameters:\n",
    "        company_data (dict): Dictionary of DataFrames keyed by ticker symbol.\n",
    "        ticker (str): The ticker symbol of the company to plot (e.g., 'AAPL').\n",
    "        window (int): Rolling window size for smoothing (default is 5 days).\n",
    "    \"\"\"\n",
    "    if ticker not in company_data:\n",
    "        print(f\"Ticker '{ticker}' not found in company data.\")\n",
    "        return\n",
    "\n",
    "    df = company_data[ticker].copy()\n",
    "    \n",
    "    # Ensure the data is sorted by date\n",
    "    df = df.sort_values(by='Date')\n",
    "\n",
    "    # Compute the smoothed values\n",
    "    df['Smoothed'] = df['Close'].rolling(window=window).mean()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df['Date'], df['Close'], label='Raw Close', alpha=0.7)\n",
    "    plt.plot(df['Date'], df['Smoothed'], label=f'Smoothed ({window}-day Avg)', color='orange', linewidth=2)\n",
    "\n",
    "    plt.title(f\"{ticker} - Raw vs Smoothed Closing Price Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Close\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2af9cb9-2097-4e39-82d4-bcd6f859aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e40536-1787-45cd-a42f-6c109a359f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='AMZN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f737e52-8999-4e2d-9afd-b3fcf1ecd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='CHL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcc1329-13d1-447f-b29c-9478e317e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='CSCO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38931aa1-ac65-4303-b9a2-25d9105f5662",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='FB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293791a-b141-4eb4-94bb-efec508bdc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='GOOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e50e8-a991-464a-999d-6ab50958c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='INTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0101a51-1881-4582-91f8-949fc30bf962",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806100d-8079-431d-b586-5c9339f9a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='ORCL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563731ad-35c5-4eb5-81bc-bc47cd259de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44eeb9-2140-468d-b020-0accaa33ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='TSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b06be1-b115-46fc-92f0-c809f9f59d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_movement(company_data, ticker='VZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b07f01-e1cd-413b-9f2e-dafc1b921a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the sentiment score based on its label\n",
    "def normalize_sentiment(label, score):\n",
    "    if label == \"positive\":\n",
    "        return score  # Keep positive scores as they are\n",
    "    elif label == \"neutral\":\n",
    "        return 0  # Neutral sentiment contributes 0 to the average\n",
    "    elif label == \"negative\":\n",
    "        return -score  # Negative sentiment becomes negative\n",
    "    else:\n",
    "        return 0  # Default to 0 for any unrecognized labels\n",
    "\n",
    "def load_sentiment_data(sentiment_folder):\n",
    "    sentiment_data = {}\n",
    "\n",
    "    # Loop through all companies in the folder\n",
    "    for company in os.listdir(sentiment_folder):\n",
    "        print(f\"Checking: {company}\")  # debug\n",
    "        company_folder = os.path.join(sentiment_folder, company)\n",
    "        if not os.path.isdir(company_folder):\n",
    "            print(f\"Skipped {company} (not a directory)\")\n",
    "            continue\n",
    "\n",
    "        daily_scores = []\n",
    "\n",
    "        # Loop through all files for the company\n",
    "        for file_name in os.listdir(company_folder):\n",
    "            file_path = os.path.join(company_folder, file_name)\n",
    "\n",
    "            # Ignore hidden or system files\n",
    "            if file_name.startswith('.') or not os.path.isfile(file_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    scores = []\n",
    "                    for line in f:\n",
    "                        tweet = json.loads(line.strip())\n",
    "                        sentiment = tweet.get(\"sentiment\", {})\n",
    "                        label = sentiment.get(\"label\")\n",
    "                        score = sentiment.get(\"score\")\n",
    "                        if score is not None and label:\n",
    "                            # Normalize sentiment based on the label\n",
    "                            normalized_score = normalize_sentiment(label, score)\n",
    "                            scores.append(normalized_score)\n",
    "\n",
    "                # If there are scores for the day, compute the average sentiment\n",
    "                if scores:\n",
    "                    avg_score = sum(scores) / len(scores)\n",
    "                    date_str = file_name.replace('.json', '')  # Use filename as date\n",
    "                    daily_scores.append({\"Date\": date_str, \"Sentiment\": avg_score})\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "        # If daily scores are collected, process and store them\n",
    "        if daily_scores:\n",
    "            df = pd.DataFrame(daily_scores)\n",
    "            df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "            df.dropna(subset=['Date'], inplace=True)  # Remove rows with invalid dates\n",
    "            df.sort_values(by=\"Date\", inplace=True)  # Sort by date\n",
    "            sentiment_data[company] = df\n",
    "            print(f\"Loaded {len(df)} days for {company}\")\n",
    "        else:\n",
    "            print(f\"No data collected for {company}\")\n",
    "\n",
    "    return sentiment_data\n",
    "\n",
    "\n",
    "# Load data\n",
    "sentiment_folder = 'tweet/preprocessed'\n",
    "sentiment_data = load_sentiment_data(sentiment_folder)\n",
    "\n",
    "# Show example\n",
    "if \"AAPL\" in sentiment_data:\n",
    "    print(sentiment_data[\"AAPL\"].head())\n",
    "else:\n",
    "    print(\"AAPL data not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a82c4-7a65-41d7-994b-4441ec4d0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find missing dates for each company's sentiment data\n",
    "def find_missing_dates(sentiment_data):\n",
    "    # Define the full date range (Jan 1st 2014 to Dec 31st 2015)\n",
    "    all_dates = pd.date_range(start=\"2014-01-01\", end=\"2015-12-31\", freq='D')\n",
    "\n",
    "    # Loop through each company's data to check for missing dates\n",
    "    for company, df in sentiment_data.items():\n",
    "        # Convert the 'Date' column to a set of dates\n",
    "        company_dates = set(df['Date'])\n",
    "\n",
    "        # Find the missing dates by subtracting the company dates from the full date range\n",
    "        missing_dates = set(all_dates) - company_dates\n",
    "\n",
    "        if missing_dates:\n",
    "            print(f\"Missing dates for {company}: {sorted(missing_dates)}\")\n",
    "        else:\n",
    "            print(f\"All dates present for {company}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2964e-582a-480a-af6b-5ae70dbb75e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge sentiment data with stock data\n",
    "def merge_sentiment_and_stock_data(stock_data, sentiment_data, company):\n",
    "    if company not in stock_data or company not in sentiment_data:\n",
    "        print(f\"Data not available for {company}\")\n",
    "        return None\n",
    "    \n",
    "    # Merge stock data with sentiment data on 'Date'\n",
    "    stock_df = stock_data[company]\n",
    "    sentiment_df = sentiment_data[company]\n",
    "    \n",
    "    # Merge the two dataframes based on 'Date'\n",
    "    merged_df = pd.merge(stock_df, sentiment_df, on='Date', how='left')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac20bb-7764-430f-bff0-da93b3d3cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_vs_stock_aligned_zero(company, stock_data, sentiment_data):\n",
    "    # Merge stock and sentiment data\n",
    "    merged_df = merge_sentiment_and_stock_data(stock_data, sentiment_data, company)\n",
    "    if merged_df is None or merged_df.empty:\n",
    "        print(f\"No data to plot for {company}\")\n",
    "        return\n",
    "\n",
    "    # Drop rows with NaN (optional: interpolate instead)\n",
    "    merged_df = merged_df.dropna(subset=['Movement %', 'Sentiment'])\n",
    "\n",
    "    # Get axis limits\n",
    "    mov_min, mov_max = merged_df['Movement %'].min(), merged_df['Movement %'].max()\n",
    "    sent_min, sent_max = merged_df['Sentiment'].min(), merged_df['Sentiment'].max()\n",
    "\n",
    "    # Find ranges around zero so both zero lines align\n",
    "    mov_range = max(abs(mov_min), abs(mov_max))\n",
    "    sent_range = max(abs(sent_min), abs(sent_max))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "    # Stock Movement %\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Stock Movement (%)', color='tab:blue')\n",
    "    ax1.plot(merged_df['Date'], merged_df['Movement %'], color='tab:blue', label='Stock Movement %')\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "    ax1.set_ylim(-mov_range, mov_range)  # Symmetrical around 0\n",
    "\n",
    "    # Sentiment Score\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Sentiment Score', color='tab:green')\n",
    "    ax2.plot(merged_df['Date'], merged_df['Sentiment'], color='tab:green', linestyle='--', label='Sentiment Score')\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "    ax2.set_ylim(-sent_range, sent_range)  # Also symmetrical\n",
    "\n",
    "    # Grid and title\n",
    "    ax1.axhline(0, color='gray', linestyle='--', linewidth=0.8)  # Zero line for clarity\n",
    "    ax2.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "    plt.title(f'{company}: Stock Movement % vs. Sentiment Score (Aligned Zero)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8e989-adf5-4448-96c3-9e697cc20374",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiment_vs_stock_aligned_zero(\"AAPL\", company_data, sentiment_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3a4de-f2aa-4e85-af01-c6850f14029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentiment_features(df, window_size=14):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Create the binary target: 1 if next day's Movement % > 0\n",
    "    df['Target'] = df['Movement %'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # Generate rolling sentiment features\n",
    "    for i in range(window_size):\n",
    "        df[f'sentiment_t-{i+1}'] = df['Sentiment'].shift(i + 1)\n",
    "\n",
    "    # Drop rows with missing values (due to shifting)\n",
    "    df = df.dropna(subset=[f'sentiment_t-{i+1}' for i in range(window_size)] + ['Target'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede82d8-bb7c-48bf-83da-64458ac15237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sentiment_model(df, window_size=14):\n",
    "    df = prepare_sentiment_features(df, window_size=window_size)\n",
    "\n",
    "    # Features and target\n",
    "    feature_cols = [f'sentiment_t-{i+1}' for i in range(window_size)]\n",
    "    X = df[feature_cols]\n",
    "    y = df['Target']\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "    # Train model\n",
    "    #model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model, X_test, y_test, y_pred, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1925fa5-4d06-47c2-806d-03de121c98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"AAPL\"\n",
    "merged_df = merge_sentiment_and_stock_data(company_data, sentiment_data, company)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate through different window sizes (from 1 to 100)\n",
    "for window_size in range(1, 50):\n",
    "    try:\n",
    "        # Call the train_sentiment_model function\n",
    "        model, X_test, y_test, y_pred, accuracy = train_sentiment_model(merged_df, window_size=window_size)\n",
    "        \n",
    "        # Store the result (window size and accuracy)\n",
    "        results.append((window_size, accuracy))\n",
    "        print(f\"Window size: {window_size} → Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Window size {window_size} failed: {e}\")\n",
    "\n",
    "# Sort the results based on accuracy in descending order\n",
    "sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted results\n",
    "print(\"\\nRanking of window sizes by accuracy:\")\n",
    "for rank, (window_size, accuracy) in enumerate(sorted_results, start=1):\n",
    "    print(f\"Rank {rank}: Window size {window_size} → Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optionally, print the best window size\n",
    "best_window, best_acc = sorted_results[0]\n",
    "print(f\"\\nBest window size: {best_window} with accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a03471-8541-48cb-a7ac-9f0f02738432",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"AAPL\"\n",
    "merged_df = merge_sentiment_and_stock_data(company_data, sentiment_data, company)\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iterate through different window sizes (from 1 to 100)\n",
    "for window_size in range(1, 50):\n",
    "    try:\n",
    "        # Call the train_sentiment_model function\n",
    "        model, X_test, y_test, y_pred, accuracy = train_sentiment_model(merged_df, window_size=window_size)\n",
    "        \n",
    "        # Store the result (window size and accuracy)\n",
    "        results.append((window_size, accuracy))\n",
    "        print(f\"Window size: {window_size} → Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Window size {window_size} failed: {e}\")\n",
    "\n",
    "# Sort the results based on accuracy in descending order\n",
    "sorted_results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the sorted results\n",
    "print(\"\\nRanking of window sizes by accuracy:\")\n",
    "for rank, (window_size, accuracy) in enumerate(sorted_results, start=1):\n",
    "    print(f\"Rank {rank}: Window size {window_size} → Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Optionally, print the best window size\n",
    "best_window, best_acc = sorted_results[0]\n",
    "print(f\"\\nBest window size: {best_window} with accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cedb32c-285f-4ad2-8fe3-19333d4b8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_movement_features(df, window_size=14):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Create binary target: 1 if next day's Movement % > 0\n",
    "    df['Target'] = df['Movement %'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # Create lag features using Movement %\n",
    "    for i in range(window_size):\n",
    "        df[f'movement_t-{i+1}'] = df['Movement %'].shift(i + 1)\n",
    "\n",
    "    # Drop rows with NaNs due to shifting\n",
    "    df = df.dropna(subset=[f'movement_t-{i+1}' for i in range(window_size)] + ['Target'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe69cb-d838-497d-9312-e93fe434f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_movement_model(df, window_size=14):\n",
    "    df = prepare_movement_features(df, window_size=window_size)\n",
    "\n",
    "    feature_cols = [f'movement_t-{i+1}' for i in range(window_size)]\n",
    "    X = df[feature_cols]\n",
    "    y = df['Target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "    # Can swap in any model here\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model, X_test, y_test, y_pred, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319955c9-01ca-4dad-bb94-ee4d6cee5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for window_size in range(1, 50):\n",
    "    try:\n",
    "        model, X_test, y_test, y_pred, accuracy = train_movement_model(merged_df, window_size=window_size)\n",
    "        results.append((window_size, accuracy))\n",
    "        print(f\"Window size: {window_size} → Accuracy: {accuracy:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Window size {window_size} failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968e8ab8-95a2-4949-895c-ee653aa0b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_price_features(df, window_size=14):\n",
    "    df = df.copy()\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # Create binary target: 1 if next day's Movement % > 0\n",
    "    df['Target'] = df['Movement %'].shift(-1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    price_cols = ['Movement %', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "    # Generate lagged features for each price-related column\n",
    "    for col in price_cols:\n",
    "        for i in range(window_size):\n",
    "            df[f'{col}_t-{i+1}'] = df[col].shift(i + 1)\n",
    "\n",
    "    # Drop rows with NaNs from shifting\n",
    "    lagged_cols = [f'{col}_t-{i+1}' for col in price_cols for i in range(window_size)]\n",
    "    df = df.dropna(subset=lagged_cols + ['Target'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e702a05-38fd-4f81-9c9e-427e6cf1055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_price_model(df, window_size=14):\n",
    "    df = prepare_price_features(df, window_size=window_size)\n",
    "\n",
    "    # Build the feature list\n",
    "    price_cols = ['Movement %', 'Open', 'High', 'Low', 'Close']\n",
    "    feature_cols = [f'{col}_t-{i+1}' for col in price_cols for i in range(window_size)]\n",
    "\n",
    "    X = df[feature_cols]\n",
    "    y = df['Target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return model, X_test, y_test, y_pred, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db430d08-79af-4436-9043-10e970f426e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_size in range(1, 50):\n",
    "    try:\n",
    "        model, X_test, y_test, y_pred, accuracy = train_price_model(merged_df, window_size=window_size)\n",
    "        results.append((window_size, accuracy))\n",
    "        print(f\"Window size: {window_size} → Accuracy: {accuracy:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Window size {window_size} failed: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
